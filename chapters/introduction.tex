%% ==============================
\chapter{Introduction}
\label{ch:Introduction}
%% ==============================

There are generally two utilized families of algorithms to render a picture from a scene description: rasterization and ray tracing. With rasterization, you start with the objects and splat them onto the view frustum. This performs very well and with various extending techniques creates very good looking, but not necessarily physically correct, results.  Rasterization is very common for real-time applications and graphics card pipelines are highly optimized for it. On the other hand ray tracing is usually considered slow and runs on the CPU\footnote{Exceptions and new advancements exist, see for example NVIDIA RTX.}, so use cases are more limited, but actually tracing light paths from light sources to the lens is a necessity to allow for physically correct and unbiased estimation of a scenes light transport.

Because of the quite intricate nature of light itself (e.g. wave-particle dualism) it is not really possible to solve the light transport equation with a basically infinite number of dimensions. The solution is to explore as many, hopefully important, light paths as possible with each decision for the path construction done probabilistically. For each event that gets chosen by a random variable, the result is later divided by the probability of its occurrence. More specifically the continuous integrals are estimated with the Monte Carlo integration, allowing the estimation of a continuous function with only a limited number of samples. We describe these concepts in more detail in chapter~\ref{ch:Fundamentals}.

When constructing the paths there are many choices and considerations one can take. Should you start at the eye or the light source, or both and later connect the path segments? How to compute the reflection on a surface? How does the medium affect the current path and refraction? Can you adjust the probabilities based on a preprocess or guide paths based on preceding path calculations?
These questions spark a variety of techniques and sub-techniques, our Photon-based Next Event Estimation (PNEE) is one of them. Acknowledging the existence and possible suitability of techniques like Bidirectional Path-tracing (BDPT), Metropolis light transport and others, throughout this work we focus our discussion only on path tracing without loss of applicability to the aforementioned.

With path tracing each path is started at the eye and only one refraction is considered at each intersection. The depth of the path is commonly limited by Russian Roulette (RR). For each pixel, a multitude of paths are started from random positions within the pixel (providing free Anti-aliasing). Aside from the single main path which covers indirect lighting, it is very effective to use Next Event Estimation (NEE) at every intersection point. NEE does estimate the direct lighting by deterministically connecting each intersection point to a light source. The rendering equation can be split up into a direct and indirect lighting part to enable this without introducing bias (see section~\ref{sec:NEE}).

With an ever-expanding complexity of modeled scenes, the presence of many light sources greatly contributes to a natural and appealing image. Choosing the most contributing light sources for NEE thus gets more and more important, with modern path tracers taking up to 50\% of today's rendering time for direct lighting calculations, mainly because evaluating the visibility term is costly. Many lights usually lead to many occluded respectively localized light influences. As the incident light integral is estimated with finitely many samples with Monte Carlo Integration the variance of this estimation is greatly dependant on how well the sampling probabilities fit the estimated function. For this reason, estimating good probability density functions (PDF) over the importance of light sources is a promising topic for research.

In this work, we present a novel technique, Photon-based Next Event Estimation (PNEE). The idea is to scatter out photons from the light sources and use them to build up a data structure which later can be used to build a PDF within the integrator. There are several design decisions that can be made through the phases of PNEE.

\begin{itemize}
    \item how to shoot photons
    \item what to store
    \item which acceleration data structure to use
    \item how to interpolate the result
\end{itemize}

For each of this phases, we explore several sub-techniques, combine them and evaluate them against each other as well as other established techniques for NEE. We achieved speedups between 50-100x in balanced test scenes, with the efficiency further scaling up as the lighting complexity of the scene increases. Nonetheless, all techniques have their own special kinds of artifacts that may not show up in the MSE but can be very irritating for a human observer. We mitigate these problems effectively and present strong results within three different test scenes that cover a high range of lighting situations.

\unsure{The source code is probably nice. Should I exclude the masterthesis repo though? It is the latex code of the document.}
\blfootnote{
All sources, test scenes, test results and images can be found at:

\begin{itemize}
    \item \url{https://github.com/AndiMiko/pbrt-v3}
    \item \url{https://github.com/AndiMiko/pbrt-scenes}
    \item \url{https://github.com/AndiMiko/PNEE-data}
    \item \url{https://github.com/AndiMiko/masterthesis} 
\end{itemize}
}