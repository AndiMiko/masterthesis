%% ==============================
\chapter{Introduction}
\label{ch:Introduction}
%% ==============================

There are generally two methods to render a picture from a scene description: rasterization and ray tracing. With rasterization you start with the objects and splat them onto the view frustum. This performs very well and with various extending techniques creates very good looking, but not necessary physically correct, results.  Rasterization is very common for real-time applications and graphic card pipelines are highly optimized for it. On the other hand ray tracing is usually considered slow and runs on the CPU, so use cases are more limited, but actually tracing light paths from light sources to the lense is a necessity to allow for physically correct and unbiased estimation of a scenes light transport. \unsure{Gibt es wirklich nur 2 methoden? Es gibt auch auf ray tracing optimierte Grafik Karten? Viele Kleinigkeiten, sind alle getroffenen Annahmen korrekt?}

Because of the quite intricate nature of light itself (e.g. wave-particle dualism) it is not really possible to solve the light transport equation with a basically infinite number of dimensions. The solution is to explore as many, hopefully important, light paths as possible with each decision for the path construction done probabilistically. For each event that gets chosen by a random variable the result is later divided by the probability of its occurrence. More specifically the continuous integrals are estimated with the Monte Carlo integration, allowing the estimation of a continuous function with only a limited number of samples. We describe these concepts in more detail in chapter~\ref{ch:Fundamentals}.

When constructing the paths there are many choices and considerations one can take. Should you start at the eye or the light source, or both and later connect the path segments? How to compute the reflection on a surface? How does the medium affect the current path and refraction? Can you adjust the probabilities based on a preprocess or guide paths based on precending path calculations?
These questions spark a variety of techniques and sub-techniques, our Photon-based Next Event Estimation (PNEE) is one of them. Acknowledging the existence and possible suitability of techniques like Bidirectional Path-tracing (BDPT), Metropolis light transport and others, throughout this work we focus our discussion only on path tracing without loss of applicability to the aforementioned.

With path tracing each path is started at the eye and only one refraction is considered at each intersection. The depth of the path is commonly limited by Russian Roulette (RR). For each pixel a multitude of paths are started from random positions within the pixel (providing free Anti-aliasing). Aside from the single main path which covers indirect lighting it is very effective to use Next Event Estimation (NEE) at every intersection point. NEE does estimate the direct lighting by deterministically connecting each intersection point to a light source. The rendering equation can be split up into a direct and indirect lighting part to enable this without introducing bias (see section~\ref{sec:NEE}).

With an ever expanding complexity of modelled scenes the presence of many light sources greatly contributes to a natural and appealing image. Choosing the best light sources for NEE thus gets more and more important, with modern path tracers taking up to 50\% of today's rendering time, partially because calculating the visibility term is costly. Many lights usually lead to many occluded respectively localized light influences. As the incident light integral is estimated with finitely many samples with Monte Carlo Integration the variance of this estimation is greatly dependant on how well the sampling probabilities fit the estimated function. For this reason estimating good probability density functions (PDF) over the importance of light sources is a promissing topic for research.

In this work we present a novel technique, Photon-based Next Event Estimation (PNEE). The idea is to scatter out photons from the light sources and use them to build up a data structure which later can be used to build a PDF within the integrator. There are several design decisions that can be made through the phases of PNEE.

\begin{itemize}
    \item how to shoot photons
    \item how to store photons
    \item which acceleration data structure to use
    \item how to interpolate the result
\end{itemize}

For each of this phases we explore several subtechniques, combine them and evaluate them against each other as well as other established techniques for NEE.

We evaluate the most promissing combinations and show that a speed up of 50-100x is easily achieveable. Nonetheless, all techniques have their own special kinds of artifacts that may not appear in the MSE but can be very irritating for a human observer. We mitigate these problems effectively and present strong results within three different test scenes that cover a high range of lighting situations.
