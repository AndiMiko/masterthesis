PNEE especially useful for SPPM integrators, as they use direct ligthing methods anyway but throw away the contributions of photons for the first intersection. => No additional work for PNEE!

Problem with visible voxelbounds (which does not occur on spatial because they don't do visibility tests!). Probably interpolate distribution linear between Voxels!?

Do I have to reduce the beta of a photon based on how far it flew? I think not because pdf is already in!?

Note for participating Media: PNEE can be used to drop of photons within the media and shoot them through with decreased beta.

how to do proper equal time comp.? By testing params until times are roughly equal?

look into papers for kd-tree knn-search acceleration. e.g.: "An FPGA Acceleration for the Kd-tree Search in Photon Mapping"

Problem with kNN: Always have to build new Distribution1D, linear space and time with lights!! This may be solved by subclassing Distribution1D to some extend?!

Problem with Grid: hard edges of variance on grid bounds. May be solved by interpolating Distribution1D. Needs to be subclassed so data has not to be copied to degrade to linear runtime. (Sampling from one Distribution1D takes logn steps due to binary search already)

Can CDFs be linearly interpolated, without copying in linear time? Can I sample from CDFs first and then sample the sampled CDF with the first u stretched out by the pdf to get the new u?

Which problemcases would you recommed to add to my testscene? Lights with different powers. Enclosed objects? Specular/Glass?

I want to get a measurement that is indipendent of the pixelsamples, so techniques are compareable (they should have the same value for any pixelsample setting)

Halton: what about poison disc sampling?

Normal Culling: Only for solid surfaces!? - Can you cull when sampling the CDF (don't sample lights that are not in pos. hemisphere) instead of doing so when creating the CDF (storing photon directions). Probably not, as you would have to discard sampled lights and you wouldn't know the exact sampling probablity then, introduces bias.

Can I divide only by the given subpdf without adding up the pdfs for all segments of that samplenum?

We use k-means clustering because it only works for hyper-ellipsoids (or hyper-spheres), as our result are CDFs at exactly the centroid, we don't want a complex shape potentially created by AHC to be a cluster, summing this shape into a CDF at the centroid would lead to unexpected results.

Consider ML algorithms: k-means does a good job and especially has okish runtime O(kndl?), but maybe we can improve, cause we have some kind of labeled data? AHC is not practical, dendogram may be useful, but runtime of O(n2) doesn't go well with millions of photons. Transductive SVM as semisupervised algorithm may be interessting considering we have labeled data? 

We are thinking about different kinds of interpolation. All methods needing a triangulation are potentially costly due to quadratic runtime (but only on centroids, which are limited!). Using a global interpolation (shepard/rbf) may be good, but we have to limit the number of influencing cdfs without visible cliffs.

Shoot photons, perform k-means to find cdf centroids, then shoot many more photons adding weights into the cdfs. This may reduce the complexitiy of the cluster analysis? (but adding new photons is costlier)

how meaningful is a voxel? count photons arriving and based on that number divided by photon count set mincontributionscale per voxel. (this would degenerate to uniform sampling where not much light is!?) --> bad if most photons are somewhere else, but this part is important nonetheless

Precompute gradient (Ableitung der 3D Funktion) in the grid of cdfs, with this make a even smoother interpolation with Hermite Splines. Bicubic interpolation may not be feasable due to 64 cdfs needed ...

Radial Basis Functions are not possible? We would need to precompute weights for a lightnum-dimensional function over the whole scene!?

What do you think of dblp?

How to handle extreme points (divide by zero) for shepard interpolation?

RBF can't be used, while the Kernel is only dependant on the distance, the weights have to be precomputed knowing the function values. The function values for ours CDFs are n-dimensional. Only n RBF interpolations would make sense? Instead use Kernel Regression for Approximation. This is also what our interpolated CDF expects as weights and thus allows for sublinear sampling.

1.0 thesis examples?

How to test/evaluate parameters? especially dependant parameters. Can I rely on one pixel sample test @ 128?

Why does .exr file has inf pixel value?

Which other scenes should I use?

Is it correct to double the step for pixel samples, or do you have to be more precise in the higher range?

how to interpret the charts?

include preprocess in the charts?

use optimal parameters in comparison? Which one to use for foreign techniques? Can parameters be adjusted for higher runtimes?

compare against ps instead time, because time will amortize when other effects make ps heavy?

Notation var/MSE?

Conflicting notations in notation list?

need a list of current related work from siggraph asia

notation: how to express in text that i is \in R and \in (0,1] for example

split the a-e figure up maybe?

read
Approximate K-Means++ in Sublinear Time
http://www.mmds.org/



Writing:

how long can I refer to an introduced variable e.g. k?

4.1 Form of storage, empty section ok?